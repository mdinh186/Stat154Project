<<<<<<< HEAD
custom_col = c("#000000", "#009E73", "#0072B2", "#D55E00")
model_roc_plot(model_list1, custom_col)
plot(model_list1, custom_col)
model_list1
=======
dat[education %in% level1] = "Less than Highschool"
dat = cbind(df)
dat = cbind(df)
dat[education %in% level1,] = "Less than highschool"
dat = cbind(df)
dat$education = as.character(dat$education)
level1 = c(" 1st-4th", " 5th-6th", " 7th-8th")
names(dat)
dat[,education := ifelse(education %in% level1, "Less than highschool",education)]
unique(dat$education)
combine_education = function(dat){
dat$education = as.character(dat$education)
level1 = c(" Preschool"," 1st-4th", " 5th-6th", " 7th-8th")
dat[,education := ifelse(education %in% level1, "Less than highschool",education)]
level2 = c(" 9th", " 10th", " 11th", " 12th")
dat[,education := ifelse(education %in% level2, "HS with degree",education)]
dat[,education := ifelse(education == " HS-grad", "HS degree",education)]
level3 = c(" Assoc-acdm"," Assoc-voc")
dat[,education := ifelse(education %in% level3, "Associate degree",education)]
}
df_feat =  combine_education(df)
combine_education = function(dat){
dat$education = as.character(dat$education)
level1 = c(" Preschool"," 1st-4th", " 5th-6th", " 7th-8th")
dat[,education := ifelse(education %in% level1, "Less than highschool",education)]
level2 = c(" 9th", " 10th", " 11th", " 12th")
dat[,education := ifelse(education %in% level2, "HS with degree",education)]
dat[,education := ifelse(education == " HS-grad", "HS degree",education)]
level3 = c(" Assoc-acdm"," Assoc-voc")
dat[,education := ifelse(education %in% level3, "Associate degree",education)]
return (dat)
}
df_feat =  combine_education(df)
View(df_feat)
unique(df_feat$education)
ggplot(df, aes(x = education, fill = income)) + geom_col()
ggplot(df, aes(x = education, fill = income, y = count)) + geom_col()
t = table(df_feat$education, df_feat$income)
t
hist(t)
edu_income = table(df_feat$education, df$income)
rownames(edu_income)
names(edu_income)
colnames(edu_income)
edu_income = data.table(Degree = rownames(edu_income), Less_50k = edu_income$` <=50K`, More_50k = edu_income$` >50K`)
class(edu_income)
edu_income[,1]
edu_income = data.table(Degree = rownames(edu_income), Less_50k = edu_income[,1], More_50k = edu_income[,2])
edu_income
edu_income = t(edu_income)
edu_income
df_feat =  combine_education(df)
edu_income = table(df_feat$education, df$income)
edu_income = data.table(Degree = rownames(edu_income), Less_50k = edu_income[,1], More_50k = edu_income[,2])
edu_income = melt(edu_income, id.vars = "Degree", measure.vars = 2:3)
head(edu_income)
ggplot(edu_income, aes(factor(Degree), value, fill = variable)) +
geom_bar(stat="identity", position = "dodge") +
scale_fill_brewer(palette = "Set1") +
labs(x = "Degree",y = "Income")
degree
dat = cbind(df_feat)
unique(dat$education)
ombine_education = function(dat){
dat$education = as.character(dat$education)
level1 = c(" Preschool"," 1st-4th", " 5th-6th", " 7th-8th")
dat[,education := ifelse(education %in% level1, "Less than highschool",education)]
level2 = c(" 9th", " 10th", " 11th", " 12th")
dat[,education := ifelse(education %in% level2, "HS with no degree",education)]
dat[,education := ifelse(education == " HS-grad", "HS degree",education)]
level3 = c(" Assoc-acdm"," Assoc-voc")
dat[,education := ifelse(education %in% level3, "Associate degree",education)]
return (dat)
}
df_feat =  combine_education(df)
combine_education = function(dat){
dat$education = as.character(dat$education)
level1 = c(" Preschool"," 1st-4th", " 5th-6th", " 7th-8th")
dat[,education := ifelse(education %in% level1, "Less than highschool",education)]
level2 = c(" 9th", " 10th", " 11th", " 12th")
dat[,education := ifelse(education %in% level2, "HS with no degree",education)]
dat[,education := ifelse(education == " HS-grad", "HS degree",education)]
level3 = c(" Assoc-acdm"," Assoc-voc")
dat[,education := ifelse(education %in% level3, "Associate degree",education)]
return (dat)
}
df_feat =  combine_education(df)
edu_income = table(df_feat$education, df$income)
edu_income = data.table(Degree = rownames(edu_income), Less_50k = edu_income[,1], More_50k = edu_income[,2])
edu_income = melt(edu_income, id.vars = "Degree", measure.vars = 2:3)
ggplot(edu_income, aes(factor(Degree), value, fill = variable)) +
geom_bar(stat="identity", position = "dodge") +
scale_fill_brewer(palette = "Set1") +
labs(x = "Degree",y = "Income")
dat = cbind(df_feat)
unique(dat$education)
combine_education = function(dat){
dat$education = as.character(dat$education)
level1 = c(" Preschool"," 1st-4th", " 5th-6th", " 7th-8th")
dat[,education := ifelse(education %in% level1, "Less than highschool",education)]
level2 = c(" 9th", " 10th", " 11th", " 12th")
dat[,education := ifelse(education %in% level2, "HS with no degree",education)]
dat[,education := ifelse(education == " HS-grad", "HS degree",education)]
level3 = c(" Assoc-acdm"," Assoc-voc")
dat[,education := ifelse(education %in% level3, "Associate degree",education)]
level4 = c(" Prof-school", " Doctorate")
dat[,education := ifelse(education %in% level4, "Doctorate or Professional degree",education)]
return (dat)
}
df_feat =  combine_education(df)
edu_income = table(df_feat$education, df$income)
edu_income = data.table(Degree = rownames(edu_income), Less_50k = edu_income[,1], More_50k = edu_income[,2])
edu_income = melt(edu_income, id.vars = "Degree", measure.vars = 2:3)
ggplot(edu_income, aes(factor(Degree), value, fill = variable)) +
geom_bar(stat="identity", position = "dodge") +
scale_fill_brewer(palette = "Set1") +
labs(x = "Degree",y = "Income")
mean(c(78002,  78157))
dat = cbind(df_feat)
unique(dat$education)
combine_education = function(dat){
dat$education = as.character(dat$education)
level1 = c(" Preschool"," 1st-4th", " 5th-6th", " 7th-8th")
dat[,education := ifelse(education %in% level1, "Less than highschool",education)]
level2 = c(" 9th", " 10th", " 11th", " 12th")
dat[,education := ifelse(education %in% level2, "HS with no degree",education)]
dat[,education := ifelse(education == " HS-grad", "HS",education)]
level3 = c(" Assoc-acdm"," Assoc-voc")
dat[,education := ifelse(education %in% level3, "Associate",education)]
level4 = c(" Prof-school", " Doctorate")
dat[,education := ifelse(education %in% level4, "Doctorate or Professional",education)]
return (dat)
}
df_feat =  combine_education(df)
edu_income = table(df_feat$education, df$income)
edu_income = data.table(Degree = rownames(edu_income), Less_50k = edu_income[,1], More_50k = edu_income[,2])
edu_income = melt(edu_income, id.vars = "Degree", measure.vars = 2:3)
ggplot(edu_income, aes(factor(Degree), value, fill = variable)) +
geom_bar(stat="identity", position = "dodge") +
scale_fill_brewer(palette = "Set1") +
labs(x = "Degree",y = "Income")
dat = merge(dat, degree_median_income, by = "education")
education_median = function(dat){
degree = unique(dat$education)
degree_median_income = data.frame(education = degree,
Mean-income = c(52370,30071, 17543,61045,35879,40258, 14275,78079))
education_median = function(dat){
degree = unique(dat$education)
degree_median_income = data.frame(education = degree,
Mean-income = c(52370,30071,17543,61045,35879,40258,14275,78079))
degree = unique(dat$education)
degree_median_income = data.frame(education = degree,
Mean-income = c(52370,30071,17543,61045,35879,40258,14275,78079))
degree_median_income = data.frame(education = degree,
Mean_income = c(52370,30071,17543,61045,35879,40258,14275,78079))
education_median = function(dat){
degree = unique(dat$education)
degree_median_income = data.frame(education = degree,
Mean_income = c(52370,30071,17543,61045,35879,40258,14275,78079))
dat = merge(dat, degree_median_income, by = "education")
return (dat)
}
df_feat = education_median(df_feat)
head(df_feat)
combine_education = function(dat){
dat$education = as.character(dat$education)
level1 = c(" Preschool"," 1st-4th", " 5th-6th", " 7th-8th")
dat[,education := ifelse(education %in% level1, "Less than highschool",education)]
level2 = c(" 9th", " 10th", " 11th", " 12th")
dat[,education := ifelse(education %in% level2, "HS with no degree",education)]
dat[,education := ifelse(education == " HS-grad", "HS",education)]
level3 = c(" Assoc-acdm"," Assoc-voc")
dat[,education := ifelse(education %in% level3, "Associate",education)]
level4 = c(" Prof-school", " Doctorate")
dat[,education := ifelse(education %in% level4, "Doctorate or Professional",education)]
return (dat)
}
df_feat =  combine_education(df)
edu_income = table(df_feat$education, df$income)
edu_income = data.table(Degree = rownames(edu_income), Less_50k = edu_income[,1], More_50k = edu_income[,2])
edu_income = melt(edu_income, id.vars = "Degree", measure.vars = 2:3)
ggplot(edu_income, aes(factor(Degree), value, fill = variable)) +
geom_bar(stat="identity", position = "dodge") +
scale_fill_brewer(palette = "Set1") +
labs(x = "Degree",y = "Income")
education_median = function(dat){
degree = unique(dat$education)
degree_median_income = data.frame(education = degree,
Edu_Mean_income = c(52370,30071,17543,61045,35879,40258,14275,78079))
dat = merge(dat, degree_median_income, by = "education")
return (dat)
}
df_feat = education_median(df_feat)
head(df_feat)
nlevels(df$native_country)
length(unique(df$native_country))
names(df)
sum(df$`hour-per-week` == 99)
nrow(df)
table(df$`hour-per-week`)
t = df[`hour-per-week` >= 55,]
table(t$`hour-per-week`, t$income)
View(t)
View(table(t$`hour-per-week`, t$income))
table(t$`martial-status`, t$`hour-per-week`)
table(df$`martial-status`, df$`hour-per-week`)
names(df)
t = df[, c("sex", "martial-status", "income")]
View(t)
table(t$sex, t$`martial-status`, t$income)
plot(table(t$sex, t$`martial-status`, t$income))
plot(table(t$sex, t$`martial-status`, t$income), ces = 5.5)
plot(table(t$sex, t$`martial-status`, t$income), ces = 0.5)
plot(table(t$sex, t$`martial-status`, t$income), cex = 0.5)
plot(table(t$sex, t$`martial-status`, t$income), cex = 0.2)
plot(table(t$sex, t$`martial-status`, t$income), cex = 0.35)
plot(table(t$sex, t$`martial-status`, t$income), cex = 0.35, side =2)
plot(table(t$sex, t$`martial-status`, t$income), cex = 0.35, las =1)
table(t$sex, t$`martial-status`
)
names(df)
range(df$age)
seq(24,90, 10)
cut(df_feat$age, c(seq(24,74, 10), 90)
)
cut(df_feat$age, c(seq(17,24,74, 10), 90)
)
cut(df_feat$age, c(seq(14,74, 10), 90))
cut(df_feat$age, c(seq(14,74, 10), 90), labels =  T)
cut(df_feat$age, c(seq(14,74, 10), 90), labels = seq("a", "g"))
cut(df_feat$age, c(seq(14,74, 10), 90), labels = 1:7)
df_feat$age = cut(df_feat$age, c(seq(14,74, 10), 90), labels = 1:7)
View(df_feat)
df_feat$age = as.factor(df_feat$age)
unique(df_feat$race)
table(df_feat$race, df_feat$income)
dat = cbind(df_feat)
race = unique(dat$race)
race
dat$race = as.character(dat$race)
race = unique(dat$race)
race
table(df_feat$age, df$`hour-per-week`)
plot(table(t$sex, t$`martial-status`, t$income), cex = 0.35, side =2)
plot(table(df_feat$race, df_feat$age, df_feat$income), las =1)
plot(table(df_feat$race, df_feat$sex, df_feat$income), las =1)
plot(table(df_feat$sex,df_feat$race,df_feat$income), las =1)
plot(table(df_feat$sex,df_feat$race,df_feat$income), las =1, title = "Cross ratio between Gender, Ethicity, and Income")
plot(table(df_feat$sex,df_feat$race,df_feat$income), las =1, main = "Cross ratio between Gender, Ethicity, and Income")
able(df_feat$sex,df_feat$race,df_feat$income
)
table(df_feat$sex,df_feat$race,df_feat$income)
unique(dat$race)
t1 = unique(dat$race)
t2 = unique(dat$sex)
t(t1)%*% t2
unique(dat$sex)
sex = as.character(dat$sex)
nmin = min(table(ytrain_origin))
rm(list = ls())
>>>>>>> upstream/master
library(rpart)
library(randomForest)
library(data.table)
library(caret)
library(doParallel)
library(plotROC)
<<<<<<< HEAD
install.packages("plotROC")
library(plotROC)
library(plotROC)
library(dplyr)
library(purrr)
library(pROC)
model_roc_plot = function(model_list, custom_col, AUC= FALSE){
# Function that takes in different models, calculate the AUC,
# and plot the ROC curve. Return AUC if specified
#   Argument:
#   model_list: list of models (that train on train on train dataset, we can use predict on those models to predict data)
#   custom_col: vector of color for each model. The length of vector should be equal to the length of model
if (length(custom_col) != length(model_list)){
stop("Model list and number of colors to plot must be equal")
}
test_roc <- function(model, data){
#     Cacluate AUC
#
roc(data$income,
predict(model, data, type = "prob")[, "More.50k"])
}
model_list_pr = model_list %>%
map(test_roc, data = train_origin)
results_list_roc <- list(NA)
num_mod <- 1
for(the_roc in model_list_pr){
results_list_roc[[num_mod]] =
data_frame(tpr = the_roc$sensitivities,
fpr = 1 - the_roc$specificities,
model = names(model_list)[num_mod])
num_mod = num_mod + 1
}
results_df_roc =  bind_rows(results_list_roc)
ggplot(aes(x = fpr,  y = tpr, group = model), data = results_df_roc) +
geom_line(aes(color = model), size = 1) +
scale_color_manual(values = custom_col) +
geom_abline(intercept = 0, slope = 1, color = "gray", size = 1) +
theme_bw(base_size = 18)
if (AUC == T){
area= model_list_pr %>%
map(auc)
return (area)
}
}
model_roc_plot(model_list1, custom_col)
model_roc_plot(model_list1, custom_col)
control5 = trainControl(method = "cv", number = 5, search = "random",allowParallel = TRUE,
summaryFunction = twoClassSummary,
classProbs = T)
rf_strata = train(xtrain_origin, ytrain_origin, method = "parRF",
mtry = ncol(xtrain_origin), trControl=control5,
strata = ytrain_origin, sampsize = c(50,50),
metric = "ROC")
rf_strata
pred = predict(rf_strata, xtest_origin)
confusionMatrix(ytest_origin, pred, positive = "More.50k")
control5$sampling = "down"
down_fit = train(xtrain_origin, ytrain_origin, method = "parRF",
verbose = F, metric = "ROC", mtry = ncol(xtrain_origin),
trControl = control5)
pred = predict(down_fit, xtest_origin)
down_fit
pred = predict(down_fit, xtest_origin)
confusionMatrix(ytest_origin, pred, positive = "More.50k")
control5$sampling = "up"
up_fit = train(xtrain_origin, ytrain_origin, method = "parRF",
verbose = F, metric = "ROC",  mtry = ncol(xtrain_origin),
trControl = control5)
up_fit
pred = predict(up_fit, xtest_origin)
confusionMatrix(ytest_origin, pred, positive = "More.50k")
control2 = trainControl(method = "cv", number = 5, search = "grid", allowParallel = TRUE)
fixmtry <- train(x = xtrain_origin, y = ytrain_origin, method = 'parRF',
tuneGrid = data.frame(.mtry = 16, .ntree = P2, .nodesize = P3),
tuneLength = 15, trControl=control2)
fixmtry <- train(x = xtrain_origin, y = ytrain_origin, method = 'parRF',
tuneGrid = data.frame(.mtry = 16, .ntree = param$ntree, .nodesize = param$nodesize),
tuneLength = 15, trControl=control2)
customRF <- list(type = "Classification", library = "randomForest", loop = NULL)
customRF$parameters <- data.frame(parameter = c("mtry","nodesize", "ntree"), class = rep("numeric", 2), label = c("nodesize", "ntree"))
customRF$parameters <- data.frame(parameter = c("mtry","nodesize", "ntree"), class = rep("numeric", 3), label = c("mtry", "nodesize", "ntree"))
customRF$grid <- function(x, y, len = NULL, search = "grid") {}
customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
randomForest(x, y, mtry=16, nodesize = param$nodesize, ntree=param$ntree, ...)
}
customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata)
customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata, type = "prob")
customRF$sort <- function(x) x[order(x[,1]),]
customRF$levels <- function(x) x$classes
customRF
fixmtry <- train(x = xtrain_origin, y = ytrain_origin, method = 'customRF',
tuneGrid = data.frame(.mtry = 16, .ntree = seq(50, 300, 50), .nodesize = seq(20, 100, 20)),
tuneLength = 15, trControl=control2)
customRF
data.frame(.mtry = 16, .ntree = seq(50, 300, 50), .nodesize = seq(20, 100, 20))
expand.grid(.mtry = 16, .ntree = seq(50, 300, 50), .nodesize = seq(20, 100, 20))
fixmtry <- train(x = xtrain_origin, y = ytrain_origin, method = 'customRF',
tuneGrid = expand.grid(.mtry = 16, .ntree = seq(50, 300, 50), .nodesize = seq(20, 100, 20)),
tuneLength = 15, trControl=control2)
fixmtry <- train(x = xtrain_origin, y = ytrain_origin, method = 'parRF',
tuneGrid = expand.grid(.mtry = 16, .ntree = seq(50, 300, 50), .nodesize = seq(20, 100, 20)),
tuneLength = 15, trControl=control2)
fixmtry <- train(x = xtrain_origin, y = ytrain_origin, method = 'parRF',
tuneGrid = expand.grid(mtry = 16, ntree = seq(50, 300, 50), nodesize = seq(20, 100, 20)),
tuneLength = 15, trControl=control2)
expand.grid(mtry = 16, ntree = seq(50, 300, 50), nodesize = seq(20, 100, 20))
fixmtry <- train(x = xtrain_origin, y = ytrain_origin, method = 'parRF',
tuneGrid = expand.grid(mtry = 16, ntree = seq(50, 300, 50), nodesize = seq(20, 100, 20)),
tuneLength = 15, trControl=control2)
rfParam <- expand.grid(ntree=seq(50, 300, 50), nodesize = seq(20, 100, 20), importance=TRUE)
fixmtry <- train(x = xtrain_origin, y = ytrain_origin, method = 'customRF',
tuneGrid = rfParam,
tuneLength = 15, trControl=control2)
fixmtry <- train(x = xtrain_origin, y = ytrain_origin, method = 'parRF',
tuneGrid = rfParam,
tuneLength = 15, trControl=control2)
library(foreach)
rfParam <- expand.grid(ntree=seq(50, 300, 50), nodesize = seq(20, 100, 20), importance=TRUE)
fixmtry <- train(x = xtrain_origin, y = ytrain_origin, method = 'parRF',
tuneGrid = rfParam,
tuneLength = 15, trControl=control2)
library("randomForest")
library("caret")
rfParam <- expand.grid(ntree=seq(50, 300, 50), nodesize = seq(20, 100, 20), importance=TRUE)
rfParam
fixmtry <- train(x = xtrain_origin, y = ytrain_origin, method = 'parRF',
tuneGrid = rfParam,
tuneLength = 15, trControl=control2)
rfParam <- expand.grid(mtry = 16, ntree=seq(50, 300, 50), nodesize = seq(20, 100, 20), importance=TRUE)
rfParam
fixmtry <- train(x = xtrain_origin, y = ytrain_origin, method = 'parRF',
tuneGrid = rfParam,
tuneLength = 15, trControl=control2)
rfParam <- expand.grid(ntree=100, importance=TRUE)
rfParam
fixmtry <- train(x = xtrain_origin, y = ytrain_origin, method = 'parRF',
tuneGrid = rfParam,
tuneLength = 15, trControl=control2)
round(sqrt(ncol(train_origin)
)
)
rfParam <- expand.grid(mtry = 4, ntree=seq(50, 300, 50), nodesize = seq(20, 100, 20), importance=TRUE)
fixmtry <- train(x = xtrain_origin, y = ytrain_origin, method = 'parRF',
tuneGrid = rfParam,
tuneLength = 15, trControl=control2)
customRF
names(caret)
names(caretFuncs)
getModelInfo(caret)
names(getModelInfo(model = "caret", regex = FALSE)[[1]]
)
getModelInfo(model = "caret", regex = FALSE)[[1]]
getModelInfo(model = "caret")
getModelInfo(model = "customRF")
caret$type
?caret
?train
customRF <- list(type = "Classification", library = "caret", loop = NULL)
customRF$parameters <- data.frame(parameter = c("mtry","nodesize", "ntree"), class = rep("numeric", 3), label = c("mtry", "nodesize", "ntree"))
customRF$grid <- function(x, y, len = NULL, search = "grid") {}
customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
randomForest(x, y, mtry=16, nodesize = param$nodesize, ntree=param$ntree, ...)
}
customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata)
customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata, type = "prob")
customRF$sort <- function(x) x[order(x[,1]),]
customRF$levels <- function(x) x$classes
customRF
rfParam <- expand.grid(mtry = 4, ntree=seq(50, 300, 50), nodesize = seq(20, 100, 20), importance=TRUE)
fixmtry <- train(x = xtrain_origin, y = ytrain_origin, method = 'customRF',
tuneGrid = rfParam,
tuneLength = 15, trControl=control2)
caret caretTheme()
caretTheme()
customRF <- list(type = "Classification", model = "caret", loop = NULL)
customRF$parameters <- data.frame(parameter = c("mtry","nodesize", "ntree"), class = rep("numeric", 3), label = c("mtry", "nodesize", "ntree"))
customRF$grid <- function(x, y, len = NULL, search = "grid") {}
customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
randomForest(x, y, mtry=16, nodesize = param$nodesize, ntree=param$ntree, ...)
}
customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata)
customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata, type = "prob")
customRF$sort <- function(x) x[order(x[,1]),]
customRF$levels <- function(x) x$classes
customRF
fixmtry <- train(x = xtrain_origin, y = ytrain_origin, method = 'customRF',
tuneGrid = rfParam,
tuneLength = 15, trControl=control2)
customRF <- list(type = "Classification", model=NULL, library = "caret", loop = NULL)
customRF$parameters <- data.frame(parameter = c("mtry","nodesize", "ntree"), class = rep("numeric", 3), label = c("mtry", "nodesize", "ntree"))
customRF$grid <- function(x, y, len = NULL, search = "grid") {}
customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
randomForest(x, y, mtry=16, nodesize = param$nodesize, ntree=param$ntree, ...)
}
customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata)
customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata, type = "prob")
customRF$sort <- function(x) x[order(x[,1]),]
customRF$levels <- function(x) x$classes
customRF
fixmtry <- train(x = xtrain_origin, y = ytrain_origin, method = 'customRF',
tuneGrid = rfParam,
tuneLength = 15, trControl=control2)
ctrol8$sampling = "smote"
customRF <- list(type = "Classification", library = "randomForest", loop = NULL)
customRF$parameters <- data.frame(parameter = c("mtry", "ntree"), class = rep("numeric", 2), label = c("mtry", "ntree"))
customRF$grid <- function(x, y, len = NULL, search = "grid") {}
customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
randomForest(x, y, mtry = param$mtry, ntree=param$ntree, ...)
}
customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata)
customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata, type = "prob")
customRF$sort <- function(x) x[order(x[,1]),]
customRF$levels <- function(x) x$classes
tunegrid <- expand.grid(.mtry=c(sqrt(ncol(x))))
tunegrid <- expand.grid(.mtry=c(1:15), .ntree=c(1000, 1500, 2000, 2500))
metric <- "Accuracy"
customRF <- list(type = "Classification", library = "randomForest", loop = NULL)
customRF$parameters <- data.frame(parameter = c("mtry", "ntree"), class = rep("numeric", 2), label = c("mtry", "ntree"))
customRF$grid <- function(x, y, len = NULL, search = "grid") {}
customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
randomForest(x, y, mtry = param$mtry, ntree=param$ntree, ...)
}
customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata)
customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata, type = "prob")
customRF$sort <- function(x) x[order(x[,1]),]
customRF$levels <- function(x) x$classes
control <- trainControl(method="repeatedcv", number=10, repeats=3)
set.seed(seed)
set.seed(123)
custom <- train(income ~ ., data=train_origin, method=customRF, metric=metric, tuneGrid=tunegrid, trControl=control)
customRF <- list(type = "Classification", library = "randomForest", loop = NULL)
customRF$parameters <- data.frame(parameter = c("mtry", "ntree", "nodesize"), class = rep("numeric", 3), label = c("mtry", "ntree", "nodesize"))
customRF$grid <- function(x, y, len = NULL, search = "grid") {}
customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
randomForest(x, y, mtry = param$mtry, ntree=param$ntree, nodesize = param$nodesize, ...)
}
customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata)
customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata, type = "prob")
customRF$sort <- function(x) x[order(x[,1]),]
customRF$levels <- function(x) x$classes
control <- trainControl(method="cv", number=10, number=5)
control <- trainControl(method="cv", number=5)
set.seed(123)
custom <- train(income ~ ., data=train_origin, method=customRF, metric=metric, tuneGrid=tunegrid, trControl=control)
tunegrid <- expand.grid(.mtry=16, .ntree=c(1000, 1500, 2000, 2500), .nodesize = seq(20, 100, 20))
metric <- "Accuracy"
control <- trainControl(method="cv", number=5)
set.seed(123)
custom <- train(income ~ ., data=train_origin, method=customRF, metric=metric, tuneGrid=tunegrid, trControl=control)
tunegrid <- expand.grid(.mtry=c(15:!6), .ntree=c(1000, 1500, 2000, 2500), .nodesize = seq(20, 100, 20))
custom <- train(income ~ ., data=train_origin, method=customRF, metric=metric, tuneGrid=tunegrid, trControl=control)
tunegrid <- expand.grid(.ntree=c(1000, 1500, 2000, 2500), .nodesize = seq(20, 100, 20))
tunegrid <- expand.grid(.ntree=c(1000, 1500, 2000, 2500), .nodesize = seq(20, 100, 20))
metric <- "Accuracy"
customRF <- list(type = "Classification", library = "randomForest", loop = NULL)
customRF$parameters <- data.frame(parameter = c("ntree", "nodesize"), class = rep("numeric", 2), label = c("mtry", "ntree", "nodesize"))
customRF$grid <- function(x, y, len = NULL, search = "grid") {}
customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
randomForest(x, y, ntree=param$ntree, nodesize = param$nodesize, ...)
}
customRF <- list(type = "Classification", library = "randomForest", loop = NULL)
customRF$parameters <- data.frame(parameter = c("ntree", "nodesize"), class = rep("numeric", 2), label = c("ntree", "nodesize"))
customRF$grid <- function(x, y, len = NULL, search = "grid") {}
customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
randomForest(x, y, ntree=param$ntree, nodesize = param$nodesize, ...)
}
customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata)
customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata, type = "prob")
customRF$sort <- function(x) x[order(x[,1]),]
customRF$levels <- function(x) x$classes
control <- trainControl(method="cv", number=5)
set.seed(123)
custom <- train(income ~ ., data=train_origin, method=customRF, metric=metric, tuneGrid=tunegrid, trControl=control, mtry = 16)
custom <- train(income ~ ., data=train_origin, method=customRF, metric=metric, tuneGrid=tunegrid, trControl=control)
rm(rfParam)
cl = makeCluster(detectCores()-1)
registerDoParallel(cl)
control <- trainControl(method="cv", number=5)
set.seed(123)
custom <- train(income ~ ., data=train_origin, method=customRF, metric=metric, tuneGrid=tunegrid, trControl=control)
summary(train_origin)
custom <- train(income ~ ., data=train_origin, method=customRF, tuneGrid=tunegrid, trControl=control)
custom <- train(x = xtrain_origin, y = ytrain_origin, method=customRF, tuneGrid=tunegrid, trControl=control)
custom <- train(x = xtrain_origin, y = ytrain_origin, method=customRF, tuneGrid=tunegrid, trControl=control
mtry = 16)
custom <- train(x = xtrain_origin, y = ytrain_origin, method=customRF, tuneGrid=tunegrid, trControl=control,
mtry = 16)
customRF <- list(type = "Classification", library = "randomForest", loop = NULL)
customRF$parameters <- data.frame(parameter = c("mtry", "ntree", "nodesize"), class = rep("numeric", 3), label = c("mtry", "ntree", "nodesize"))
customRF$grid <- function(x, y, len = NULL, search = "grid") {}
customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
randomForest(x, y, mtry = param$mtry, ntree=param$ntree, nodesize = param$nodesize, ...)
}
customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata)
customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata, type = "prob")
customRF$sort <- function(x) x[order(x[,1]),]
customRF$levels <- function(x) x$classes
tunegrid <- expand.grid(.mtry = 16, .ntree=c(1000, 1500, 2000, 2500), .nodesize = seq(20, 100, 20))
tunegrid
control <- trainControl(method="cv", number=5)
set.seed(123)
custom <- train(x = xtrain_origin, y = ytrain_origin, method=customRF, tuneGrid=tunegrid, trControl=control,
mtry = 16)
custom <- train(x = xtrain_origin, y = ytrain_origin, method=customRF, tuneGrid=tunegrid, trControl=control)
tunegrid <- expand.grid(.mtry = c(15:16), .ntree=c(1000, 1500, 2000, 2500), .nodesize = seq(20, 100, 20))
custom <- train(x = xtrain_origin, y = ytrain_origin, method=customRF, tuneGrid=tunegrid, trControl=control)
tunegrid <- expand.grid(.mtry = c(15:16), .ntree=c(1000, 1500, 2000, 2500))
tunegrid <- expand.grid(.mtry = c(15:16), .ntree=c(1000, 1500, 2000, 2500))
metric <- "Accuracy"
customRF <- list(type = "Classification", library = "randomForest", loop = NULL)
customRF$parameters <- data.frame(parameter = c("mtry", "ntree"), class = rep("numeric", 2), label = c("mtry", "ntree"))
customRF$grid <- function(x, y, len = NULL, search = "grid") {}
customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
randomForest(x, y, mtry = param$mtry, ntree=param$ntree, ...)
}
customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata)
customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata, type = "prob")
customRF$sort <- function(x) x[order(x[,1]),]
customRF$levels <- function(x) x$classes
control <- trainControl(method="cv", number=5)
set.seed(123)
custom <- train(x = xtrain_origin, y = ytrain_origin, method=customRF, tuneGrid=tunegrid, trControl=control)
customRF <- list(type = "Classification", library = "randomForest", loop = NULL)
customRF$parameters <- data.frame(parameter = c("mtry", "ntree"), class = rep("numeric", 2), label = c("mtry", "ntree"))
customRF$grid <- function(x, y, len = NULL, search = "grid") {}
customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
randomForest(x, y, mtry = param$mtry, ntree=param$ntree, ...)
}
customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata)
customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata, type = "prob")
customRF$sort <- function(x) x[order(x[,1]),]
customRF$levels <- function(x) x$classes
table(train_origin$income)
table(train_origin$income, test_origin$income)
control <- trainControl(method="cv", number=5)
tunegrid <- expand.grid(.mtry=c(1:15), .ntree=c(1000, 1500, 2000, 2500))
custom <- train(income ~ ., data=train_origin, method=customRF, metric=metric, tuneGrid=tunegrid, trControl=control)
tunegrid <- expand.grid(.mtry=c(1:16), .ntree=c(1000, 1500, 2000, 2500))
custom <- train(income ~ ., data=train_origin, method=customRF, metric=metric, tuneGrid=tunegrid, trControl=control)
custom <- train(income ~ ., data=train_origin, method="customRF", metric=metric, tuneGrid=tunegrid, trControl=control)
custom <- train(income ~ ., data=train_origin, method="treebag", metric=metric, tuneGrid=tunegrid, trControl=control)
cartModel$variable.importance
cartModel <- rpart(income ~., train_origin)
cartModel$variable.importance
printcp(cartModel)
plot(cartModel)
text(cartModel, cex = 0.5)
custom <- train(income ~ ., data=train_origin, method="treebag", metric=metric, trControl=control)
library(ipred)
control = trainControl(method = "cv", number = 5)
rf_default  = train(x = xtrain_origin, y = ytrain_origin,
method = "treebag", trControl = control,
importance= T, ntree = 100, replace= F, mtry = ncol(xtrain_origin))
rf_default
control2 = trainControl(method = "cv", number = 5, search = "grid", allowParallel = TRUE)
tunegrid = expand.grid(.ntrees = seq(50, 300, 50))
rf_gridsearch = train(xtrain_origin, ytrain_origin, method = "treebag",
tuneGrid=tunegrid, mtry = ncol(xtrain_origin),
trControl=control2)
?toString
metric <- "Accuracy"
control <- trainControl(method="cv", number=5, search="grid")
tunegrid <- expand.grid(.mtry=ncol(x))
tunegrid <- expand.grid(.mtry=ncol(xtrain_origin))
for (ntree in seq(50, 500, 50)) {
for(nodesize in c(1,5,10,50,100, 200, 250, 500)){
set.seed(seed)
fit <- train(income~., data=train_origin, method="rf", metric=metric,
tuneGrid=tunegrid, trControl=control, ntree=ntree,
nodesize = nodesize)
key <- toString(ntree)
modellist[[key]] <- fit
}
}
seed <- 123
for (ntree in seq(50, 500, 50)) {
for(nodesize in c(1,5,10,50,100, 200, 250, 500)){
set.seed(seed)
fit <- train(income~., data=train_origin, method="rf", metric=metric,
tuneGrid=tunegrid, trControl=control, ntree=ntree,
nodesize = nodesize)
key <- toString(ntree)
modellist[[key]] <- fit
}
}
metric <- "Accuracy"
control <- trainControl(method="cv", number=5, search="grid")
tunegrid <- expand.grid(.mtry=ncol(xtrain_origin))
seed <- 123
modellist <- list()
for (ntree in seq(50, 500, 50)) {
for(nodesize in c(1,5,10,50,100, 200, 250, 500)){
set.seed(seed)
fit <- train(income~., data=train_origin, method="rf", metric=metric,
tuneGrid=tunegrid, trControl=control, ntree=ntree,
nodesize = nodesize)
key <- toString(ntree)
modellist[[key]] <- fit
}
}
metric <- "Accuracy"
control <- trainControl(method="cv", number=5, search="grid")
tunegrid <- expand.grid(.mtry=ncol(xtrain_origin))
seed <- 123
modellist <- list()
for (ntree in seq(50, 500, 50)) {
set.seed(seed)
fit <- train(income~., data=train_origin, method="rf", metric=metric,
tuneGrid=tunegrid, trControl=control, ntree=ntree)
key <- toString(ntree)
modellist[[key]] <- fit
}
modellist
results <- resamples(modellist)
summary(results)
control <- trainControl(method="cv", number=5, search="grid")
tunegrid <- expand.grid(.mtry=ncol(xtrain_origin))
seed <- 123
modellist <- list()
for (ntree in c(1,5,10,50,100)) {
set.seed(seed)
fit <- train(income~., data=train_origin, method="rf", metric=metric,
tuneGrid=tunegrid, trControl=control, ntree=ntree)
key <- toString(ntree)
modellist[[key]] <- fit
}
results <- resamples(modellist)
summary(results)
dotplot(results)
control <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")
for (ntree in c(1,5,10,50,100)) {
set.seed(seed)
fit <- train(income~., data=train_origin, method="rf", metric=metric,
tuneGrid=tunegrid, trControl=control, ntree=ntree)
key <- toString(ntree)
modellist[[key]] <- fit
}
ntree_test <- seq(50, 500, 50)
accuracies <- vector()
for(i in 1: length(ntree_test)){
bag <- randomForest(income~., data = train_origin, mtry = 16, importance = TRUE, ntree = ntree_test[i])
yhat.bag = predict(bag, newdata = test_origin)
test <- confusionMatrix(ytest_origin, yhat.bag, positive = "More.50k")
accuracies[i] <- (test$table[1] + test$table[4])/sum(test$table) #accuracy rate
}
train_origin <- as.data.frame(train_origin)
for(i in 1: length(ntree_test)){
bag <- randomForest(income~., data = train_origin, mtry = 16, importance = TRUE, ntree = ntree_test[i])
yhat.bag = predict(bag, newdata = test_origin)
test <- confusionMatrix(ytest_origin, yhat.bag, positive = "More.50k")
accuracies[i] <- (test$table[1] + test$table[4])/sum(test$table) #accuracy rate
}
head(train_origin)
train_origin <- data.frame(train_origin)
head(train_origin)
for(i in 1: length(ntree_test)){
bag <- randomForest(income~., data = train_origin, mtry = 16, importance = TRUE, ntree = ntree_test[i])
yhat.bag = predict(bag, newdata = test_origin)
test <- confusionMatrix(ytest_origin, yhat.bag, positive = "More.50k")
accuracies[i] <- (test$table[1] + test$table[4])/sum(test$table) #accuracy rate
}
head(train_origin)
head(test_origin)
names(test_origin)
names(test_origin) <- names(train_origin)
for(i in 1: length(ntree_test)){
bag <- randomForest(income~., data = train_origin, mtry = 16, importance = TRUE, ntree = ntree_test[i])
yhat.bag = predict(bag, newdata = test_origin)
test <- confusionMatrix(ytest_origin, yhat.bag, positive = "More.50k")
accuracies[i] <- (test$table[1] + test$table[4])/sum(test$table) #accuracy rate
}
stopCluster(cl = NULL)
stopCluster(cl = NULL)
?stopcluster
?stopCluster()
stopCluster(cl = NULL)
getDoParWorkers()
cl
stopCluster(cl)
getDoParWorkers()
=======
library(dplyr)
library(purrr)
library(pROC)
#############################################################
dir = "/Users/MyDinh/Downloads/Stat154/Stat154Project/"
setwd(dir)
set.seed(123)
df_impute = readRDS("data/df_impute_feat.rds")
df_impute = data.table(df_impute)
#saveRDS(df_impute,"data/df_impute_feat.rds")
n = ceiling(nrow(df_impute) * 0.8)
#############################################################
# Prepocessing data:
#############################################################
train_idx = sample(nrow(df_impute),n)
train_origin = df_impute[train_idx,]
test_origin = df_impute[-train_idx, ]
xtrain_origin  = train_origin[,-c("income")]
ytrain_origin = train_origin$income
xtest_origin  = test_origin[,-c("income")]
ytest_origin = test_origin$income
(1/table(ytrain_origin)[1]) * 0.5,
(1/table(ytrain_origin)[2]) * 0.5)
ctrol8 = trainControl(method = "cv", number =5,
summaryFunction = twoClassSummary,
classProbs = T)
# with weights
model_weights = ifelse(ytrain_origin == "Less.50k",
(1/table(ytrain_origin)[1]) * 0.5,
(1/table(ytrain_origin)[2]) * 0.5)
ctrol8 = trainControl(method = "cv", number =5,
summaryFunction = twoClassSummary,
classProbs = T)
nmin = min(table(ytrain_origin))
nmin = min(table(ytrain_origin))
weighted_down_fit = train(xtrain_origin, ytrain_origin, method = "rf",
tuneLength = 15, trControl=ctrol8,
strata = ytrain_origin,
sampsize = rep(nmin, 2), metric = "ROC",
weights = model_weights)
weighted_down_fit
pred = predict(weighted_down_fit, xtest_origin)
confusionMatrix(ytest_origin, pred, positive = "More.50k")
nmin = min(table(ytrain_origin))
weighted_down_fit2 = train(xtrain_origin, ytrain_origin, method = "rf",
tuneLength = 15, trControl=ctrol8,
strata = ytrain_origin,
sampsize = rep(1000, 1000), metric = "ROC",
replace = F,
weights = model_weights)
ctrol8 = trainControl(method = "cv", number =5,
summaryFunction = twoClassSummary,
classProbs = T)
weighted_down_fit2 = train(xtrain_origin, ytrain_origin, method = "rf",
tuneLength = 15, trControl=ctrol8,
strata = ytrain_origin,
sampsize = rep(1000, 1000), metric = "ROC",
replace = F,
weights = model_weights)
weighted_down_fit2 = train(xtrain_origin, ytrain_origin, method = "rf",
tuneLength = 15, trControl=ctrol8,
strata = ytrain_origin,
sampsize = rep(500, 500), metric = "ROC",
replace = F,
weights = model_weights)
nmin = min(table(ytrain_origin))
weighted_down_fit2 = train(xtrain_origin, ytrain_origin, method = "rf",
tuneLength = 15, trControl=ctrol8,
strata = ytrain_origin,
sampsize = rep(100, 100), metric = "ROC",
replace = F,
weights = model_weights)
nmin = min(table(ytrain_origin))
weighted_down_fit2 = train(xtrain_origin, ytrain_origin, method = "rf",
tuneLength = 15, trControl=ctrol8,
strata = ytrain_origin,
sampsize = rep(50, 50), metric = "ROC",
replace = F,
weights = model_weights)
weighted_down_fit2 = train(xtrain_origin, ytrain_origin, method = "rf",
tuneLength = 15, trControl=ctrol8,
strata = ytrain_origin,
metric = "ROC",
replace = F,
weights = model_weights)
weighted_down_fit
pred = predict(weighted_down_fit2, xtest_origin)
pred = predict(weighted_down_fit2, xtest_origin)
weighted_down_fit2 = train(xtrain_origin, ytrain_origin, method = "rf",
tuneLength = 15, trControl=ctrol8,
strata = ytrain_origin,
metric = "ROC",
replace = F,
weights = model_weights)
weighted_down_fit2
pred = predict(weighted_down_fit2, xtest_origin)
confusionMatrix(ytest_origin, pred, positive = "More.50k")
weighted_down_fit2
nmax  = max(table(ytrain_origin))
weighted_up_fit = train(xtrain_origin, ytrain_origin, method = "rf",
tuneLength = 15,
trControl=ctrol8,
strata = ytrain_origin,
sampsize = c(8000,8000), metric = "ROC",
weights = model_weights)
weighted_up_fit = train(xtrain_origin, ytrain_origin, method = "rf",
tuneLength = 15,
trControl=ctrol8,
strata = ytrain_origin,
sampsize = rep(nmax, 2), metric = "ROC",
weights = model_weights)
ctrol8$sampling = "smote"
weighted_smote_fit = train(xtrain_origin, ytrain_origin, method = "rf",
tuneLength = 15,
trControl=ctrol8,
strata = ytrain_origin,
metric = "ROC",
weights = model_weights)
library(grid)
ctrol8$sampling = "smote"
weighted_smote_fit = train(xtrain_origin, ytrain_origin, method = "rf",
tuneLength = 15,
trControl=ctrol8,
strata = ytrain_origin,
metric = "ROC",
weights = model_weights)
weighted_smote_fit
pred = predict(weighted_smote_fit, xtest_origin)
confusionMatrix(ytest_origin, pred, positive = "More.50k")
model_list4 = list(weighted = weighted_fit,
weighted_strata = weighted_strata,
down_weight = weighted_down_fit,
down_wight_wt_rp = weighted_down_fit2,
SMOTE_weight = weighted_smote_fit)
weighted_fit = train(xtrain_origin, ytrain_origin, method = "rf",
verbose = F,
weights = model_weights,
metric = "ROC",
trControl = ctrol8)
pred = predict(weighted_fit, xtest_origin)
confusionMatrix(ytest_origin, pred, positive = "More.50k")
set.seed(123)
library(data.table)
library(ggplot2)
library(GGally)
library(corrgram)
library(tidyr)
library(dplyr)
library(corrplot)
library(factoextra)
library(FactoMineR)
set.seed(123)
df = read.csv('/Users/MyDinh/mdinh6_data-x-f17/Project/data_final_final.csv')
df = data.table(df)
summary(df)
table(ytrain_origin)
table(ytest_origin)
df_impute = readRDS("data/df_impute_feat.rds")
df_impute = data.table(df_impute)
split1 = createDataPartition(df_impute$income, p  = 0.8)[[1]]
train_origin = df_impute[split1,]
test_origin = df_impute[-split1, ]
xtrain_origin = train_origin[, -c("income")]
ytrain_origin = train_origin$income
xtest_origin = test_origin[,-c("income")]
ytest_origin = test_origin$income
table(ytest_origin)
table(ytrain_origin)
split1 = createDataPartition(df_impute$income, p  = 0.8)[[1]]
?createDataPartition
table(ytrain_origin)/nrow(ytrain_origin) * 100
table(ytrain_origin)/nrow(ytrain_origin)
n = ceiling(nrow(df_impute) * 0.8)
#############################################################
# Prepocessing data:
#############################################################
train_idx = sample(nrow(df_impute),n)
train_origin = df_impute[train_idx,]
test_origin = df_impute[-train_idx, ]
xtrain_origin  = train_origin[,-c("income")]
ytrain_origin = train_origin$income
xtest_origin  = test_origin[,-c("income")]
ytest_origin = test_origin$income
table(ytrain_origin)
table(ytest_origin)
split1 = createDataPartition(df_impute$income, p  = 0.8)[[1]]
train_origin = df_impute[split1,]
test_origin = df_impute[-split1, ]
xtrain_origin = train_origin[, -c("income")]
ytrain_origin = train_origin$income
xtest_origin = test_origin[,-c("income")]
ytest_origin = test_origin$income
control = trainControl(method = "cv", number = 5)
rf_default  = train(x = xtrain_origin, y = ytrain_origin,
method = "rf", trControl = control,
importance= T, ntree = 100, replace= F)
rf_default
pred = predict(rf_default, xtest_origin)
confusionMatrix(ytest_origin, pred, positive = "More.50k")
varImp(rf_default)
rf_default  = train(x = xtrain_origin, y = ytrain_origin,
method = "rf", trControl = control,
importance= T, ntree = 100)
rf_d
rf_default
pred = predict(rf_default, xtest_origin)
confusionMatrix(ytest_origin, pred, positive = "More.50k")
varImp(rf_default)
ctrol = trainControl(method = "cv", number =5,
verboseIter = F,
sampling = "down")
model_rf_under = train(xtrain_origin, ytrain_origin, method = "parRF",
trControl = ctrol)
install.packages("foreach")
install.packages("foreach")
install.packages("import")
install.packages("import")
library(import)
model_rf_under = train(xtrain_origin, ytrain_origin, method = "parRF",
trControl = ctrol)
library(caret)
library(rpart)
library(randomForest)
library(data.table)
library(caret)
library(doParallel)
library(plotROC)
library(dplyr)
library(purrr)
library(pROC)
ctrol = trainControl(method = "cv", number =5,
verboseIter = F,
sampling = "down")
model_rf_under = train(xtrain_origin, ytrain_origin, method = "parRF",
trControl = ctrol)
cl = makeCluster(detectCores()-1)
registerDoParallel(cl)
model_rf_under = train(xtrain_origin, ytrain_origin, method = "parRF",
trControl = ctrol)
stopCluster(cl)
model_rf_under = train(xtrain_origin, ytrain_origin, method = "RF",
trControl = ctrol)
model_rf_under = train(xtrain_origin, ytrain_origin, method = "rf",
trControl = ctrol)
model_rf_under = train(xtrain_origin, ytrain_origin, method = "rf",
trControl = ctrol)
>>>>>>> upstream/master
