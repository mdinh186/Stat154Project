custom_col = c("#000000", "#009E73", "#0072B2", "#D55E00")
model_roc_plot(model_list1, custom_col)
plot(model_list1, custom_col)
model_list1
library(rpart)
library(randomForest)
library(data.table)
library(caret)
library(doParallel)
library(plotROC)
install.packages("plotROC")
library(plotROC)
library(plotROC)
library(dplyr)
library(purrr)
library(pROC)
model_roc_plot = function(model_list, custom_col, AUC= FALSE){
# Function that takes in different models, calculate the AUC,
# and plot the ROC curve. Return AUC if specified
#   Argument:
#   model_list: list of models (that train on train on train dataset, we can use predict on those models to predict data)
#   custom_col: vector of color for each model. The length of vector should be equal to the length of model
if (length(custom_col) != length(model_list)){
stop("Model list and number of colors to plot must be equal")
}
test_roc <- function(model, data){
#     Cacluate AUC
#
roc(data$income,
predict(model, data, type = "prob")[, "More.50k"])
}
model_list_pr = model_list %>%
map(test_roc, data = train_origin)
results_list_roc <- list(NA)
num_mod <- 1
for(the_roc in model_list_pr){
results_list_roc[[num_mod]] =
data_frame(tpr = the_roc$sensitivities,
fpr = 1 - the_roc$specificities,
model = names(model_list)[num_mod])
num_mod = num_mod + 1
}
results_df_roc =  bind_rows(results_list_roc)
ggplot(aes(x = fpr,  y = tpr, group = model), data = results_df_roc) +
geom_line(aes(color = model), size = 1) +
scale_color_manual(values = custom_col) +
geom_abline(intercept = 0, slope = 1, color = "gray", size = 1) +
theme_bw(base_size = 18)
if (AUC == T){
area= model_list_pr %>%
map(auc)
return (area)
}
}
model_roc_plot(model_list1, custom_col)
model_roc_plot(model_list1, custom_col)
control5 = trainControl(method = "cv", number = 5, search = "random",allowParallel = TRUE,
summaryFunction = twoClassSummary,
classProbs = T)
rf_strata = train(xtrain_origin, ytrain_origin, method = "parRF",
mtry = ncol(xtrain_origin), trControl=control5,
strata = ytrain_origin, sampsize = c(50,50),
metric = "ROC")
rf_strata
pred = predict(rf_strata, xtest_origin)
confusionMatrix(ytest_origin, pred, positive = "More.50k")
control5$sampling = "down"
down_fit = train(xtrain_origin, ytrain_origin, method = "parRF",
verbose = F, metric = "ROC", mtry = ncol(xtrain_origin),
trControl = control5)
pred = predict(down_fit, xtest_origin)
down_fit
pred = predict(down_fit, xtest_origin)
confusionMatrix(ytest_origin, pred, positive = "More.50k")
control5$sampling = "up"
up_fit = train(xtrain_origin, ytrain_origin, method = "parRF",
verbose = F, metric = "ROC",  mtry = ncol(xtrain_origin),
trControl = control5)
up_fit
pred = predict(up_fit, xtest_origin)
confusionMatrix(ytest_origin, pred, positive = "More.50k")
control2 = trainControl(method = "cv", number = 5, search = "grid", allowParallel = TRUE)
fixmtry <- train(x = xtrain_origin, y = ytrain_origin, method = 'parRF',
tuneGrid = data.frame(.mtry = 16, .ntree = P2, .nodesize = P3),
tuneLength = 15, trControl=control2)
fixmtry <- train(x = xtrain_origin, y = ytrain_origin, method = 'parRF',
tuneGrid = data.frame(.mtry = 16, .ntree = param$ntree, .nodesize = param$nodesize),
tuneLength = 15, trControl=control2)
customRF <- list(type = "Classification", library = "randomForest", loop = NULL)
customRF$parameters <- data.frame(parameter = c("mtry","nodesize", "ntree"), class = rep("numeric", 2), label = c("nodesize", "ntree"))
customRF$parameters <- data.frame(parameter = c("mtry","nodesize", "ntree"), class = rep("numeric", 3), label = c("mtry", "nodesize", "ntree"))
customRF$grid <- function(x, y, len = NULL, search = "grid") {}
customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
randomForest(x, y, mtry=16, nodesize = param$nodesize, ntree=param$ntree, ...)
}
customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata)
customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata, type = "prob")
customRF$sort <- function(x) x[order(x[,1]),]
customRF$levels <- function(x) x$classes
customRF
fixmtry <- train(x = xtrain_origin, y = ytrain_origin, method = 'customRF',
tuneGrid = data.frame(.mtry = 16, .ntree = seq(50, 300, 50), .nodesize = seq(20, 100, 20)),
tuneLength = 15, trControl=control2)
customRF
data.frame(.mtry = 16, .ntree = seq(50, 300, 50), .nodesize = seq(20, 100, 20))
expand.grid(.mtry = 16, .ntree = seq(50, 300, 50), .nodesize = seq(20, 100, 20))
fixmtry <- train(x = xtrain_origin, y = ytrain_origin, method = 'customRF',
tuneGrid = expand.grid(.mtry = 16, .ntree = seq(50, 300, 50), .nodesize = seq(20, 100, 20)),
tuneLength = 15, trControl=control2)
fixmtry <- train(x = xtrain_origin, y = ytrain_origin, method = 'parRF',
tuneGrid = expand.grid(.mtry = 16, .ntree = seq(50, 300, 50), .nodesize = seq(20, 100, 20)),
tuneLength = 15, trControl=control2)
fixmtry <- train(x = xtrain_origin, y = ytrain_origin, method = 'parRF',
tuneGrid = expand.grid(mtry = 16, ntree = seq(50, 300, 50), nodesize = seq(20, 100, 20)),
tuneLength = 15, trControl=control2)
expand.grid(mtry = 16, ntree = seq(50, 300, 50), nodesize = seq(20, 100, 20))
fixmtry <- train(x = xtrain_origin, y = ytrain_origin, method = 'parRF',
tuneGrid = expand.grid(mtry = 16, ntree = seq(50, 300, 50), nodesize = seq(20, 100, 20)),
tuneLength = 15, trControl=control2)
rfParam <- expand.grid(ntree=seq(50, 300, 50), nodesize = seq(20, 100, 20), importance=TRUE)
fixmtry <- train(x = xtrain_origin, y = ytrain_origin, method = 'customRF',
tuneGrid = rfParam,
tuneLength = 15, trControl=control2)
fixmtry <- train(x = xtrain_origin, y = ytrain_origin, method = 'parRF',
tuneGrid = rfParam,
tuneLength = 15, trControl=control2)
library(foreach)
rfParam <- expand.grid(ntree=seq(50, 300, 50), nodesize = seq(20, 100, 20), importance=TRUE)
fixmtry <- train(x = xtrain_origin, y = ytrain_origin, method = 'parRF',
tuneGrid = rfParam,
tuneLength = 15, trControl=control2)
library("randomForest")
library("caret")
rfParam <- expand.grid(ntree=seq(50, 300, 50), nodesize = seq(20, 100, 20), importance=TRUE)
rfParam
fixmtry <- train(x = xtrain_origin, y = ytrain_origin, method = 'parRF',
tuneGrid = rfParam,
tuneLength = 15, trControl=control2)
rfParam <- expand.grid(mtry = 16, ntree=seq(50, 300, 50), nodesize = seq(20, 100, 20), importance=TRUE)
rfParam
fixmtry <- train(x = xtrain_origin, y = ytrain_origin, method = 'parRF',
tuneGrid = rfParam,
tuneLength = 15, trControl=control2)
rfParam <- expand.grid(ntree=100, importance=TRUE)
rfParam
fixmtry <- train(x = xtrain_origin, y = ytrain_origin, method = 'parRF',
tuneGrid = rfParam,
tuneLength = 15, trControl=control2)
round(sqrt(ncol(train_origin)
)
)
rfParam <- expand.grid(mtry = 4, ntree=seq(50, 300, 50), nodesize = seq(20, 100, 20), importance=TRUE)
fixmtry <- train(x = xtrain_origin, y = ytrain_origin, method = 'parRF',
tuneGrid = rfParam,
tuneLength = 15, trControl=control2)
customRF
names(caret)
names(caretFuncs)
getModelInfo(caret)
names(getModelInfo(model = "caret", regex = FALSE)[[1]]
)
getModelInfo(model = "caret", regex = FALSE)[[1]]
getModelInfo(model = "caret")
getModelInfo(model = "customRF")
caret$type
?caret
?train
customRF <- list(type = "Classification", library = "caret", loop = NULL)
customRF$parameters <- data.frame(parameter = c("mtry","nodesize", "ntree"), class = rep("numeric", 3), label = c("mtry", "nodesize", "ntree"))
customRF$grid <- function(x, y, len = NULL, search = "grid") {}
customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
randomForest(x, y, mtry=16, nodesize = param$nodesize, ntree=param$ntree, ...)
}
customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata)
customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata, type = "prob")
customRF$sort <- function(x) x[order(x[,1]),]
customRF$levels <- function(x) x$classes
customRF
rfParam <- expand.grid(mtry = 4, ntree=seq(50, 300, 50), nodesize = seq(20, 100, 20), importance=TRUE)
fixmtry <- train(x = xtrain_origin, y = ytrain_origin, method = 'customRF',
tuneGrid = rfParam,
tuneLength = 15, trControl=control2)
caret caretTheme()
caretTheme()
customRF <- list(type = "Classification", model = "caret", loop = NULL)
customRF$parameters <- data.frame(parameter = c("mtry","nodesize", "ntree"), class = rep("numeric", 3), label = c("mtry", "nodesize", "ntree"))
customRF$grid <- function(x, y, len = NULL, search = "grid") {}
customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
randomForest(x, y, mtry=16, nodesize = param$nodesize, ntree=param$ntree, ...)
}
customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata)
customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata, type = "prob")
customRF$sort <- function(x) x[order(x[,1]),]
customRF$levels <- function(x) x$classes
customRF
fixmtry <- train(x = xtrain_origin, y = ytrain_origin, method = 'customRF',
tuneGrid = rfParam,
tuneLength = 15, trControl=control2)
customRF <- list(type = "Classification", model=NULL, library = "caret", loop = NULL)
customRF$parameters <- data.frame(parameter = c("mtry","nodesize", "ntree"), class = rep("numeric", 3), label = c("mtry", "nodesize", "ntree"))
customRF$grid <- function(x, y, len = NULL, search = "grid") {}
customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
randomForest(x, y, mtry=16, nodesize = param$nodesize, ntree=param$ntree, ...)
}
customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata)
customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata, type = "prob")
customRF$sort <- function(x) x[order(x[,1]),]
customRF$levels <- function(x) x$classes
customRF
fixmtry <- train(x = xtrain_origin, y = ytrain_origin, method = 'customRF',
tuneGrid = rfParam,
tuneLength = 15, trControl=control2)
ctrol8$sampling = "smote"
customRF <- list(type = "Classification", library = "randomForest", loop = NULL)
customRF$parameters <- data.frame(parameter = c("mtry", "ntree"), class = rep("numeric", 2), label = c("mtry", "ntree"))
customRF$grid <- function(x, y, len = NULL, search = "grid") {}
customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
randomForest(x, y, mtry = param$mtry, ntree=param$ntree, ...)
}
customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata)
customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata, type = "prob")
customRF$sort <- function(x) x[order(x[,1]),]
customRF$levels <- function(x) x$classes
tunegrid <- expand.grid(.mtry=c(sqrt(ncol(x))))
tunegrid <- expand.grid(.mtry=c(1:15), .ntree=c(1000, 1500, 2000, 2500))
metric <- "Accuracy"
customRF <- list(type = "Classification", library = "randomForest", loop = NULL)
customRF$parameters <- data.frame(parameter = c("mtry", "ntree"), class = rep("numeric", 2), label = c("mtry", "ntree"))
customRF$grid <- function(x, y, len = NULL, search = "grid") {}
customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
randomForest(x, y, mtry = param$mtry, ntree=param$ntree, ...)
}
customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata)
customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata, type = "prob")
customRF$sort <- function(x) x[order(x[,1]),]
customRF$levels <- function(x) x$classes
control <- trainControl(method="repeatedcv", number=10, repeats=3)
set.seed(seed)
set.seed(123)
custom <- train(income ~ ., data=train_origin, method=customRF, metric=metric, tuneGrid=tunegrid, trControl=control)
customRF <- list(type = "Classification", library = "randomForest", loop = NULL)
customRF$parameters <- data.frame(parameter = c("mtry", "ntree", "nodesize"), class = rep("numeric", 3), label = c("mtry", "ntree", "nodesize"))
customRF$grid <- function(x, y, len = NULL, search = "grid") {}
customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
randomForest(x, y, mtry = param$mtry, ntree=param$ntree, nodesize = param$nodesize, ...)
}
customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata)
customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata, type = "prob")
customRF$sort <- function(x) x[order(x[,1]),]
customRF$levels <- function(x) x$classes
control <- trainControl(method="cv", number=10, number=5)
control <- trainControl(method="cv", number=5)
set.seed(123)
custom <- train(income ~ ., data=train_origin, method=customRF, metric=metric, tuneGrid=tunegrid, trControl=control)
tunegrid <- expand.grid(.mtry=16, .ntree=c(1000, 1500, 2000, 2500), .nodesize = seq(20, 100, 20))
metric <- "Accuracy"
control <- trainControl(method="cv", number=5)
set.seed(123)
custom <- train(income ~ ., data=train_origin, method=customRF, metric=metric, tuneGrid=tunegrid, trControl=control)
tunegrid <- expand.grid(.mtry=c(15:!6), .ntree=c(1000, 1500, 2000, 2500), .nodesize = seq(20, 100, 20))
custom <- train(income ~ ., data=train_origin, method=customRF, metric=metric, tuneGrid=tunegrid, trControl=control)
tunegrid <- expand.grid(.ntree=c(1000, 1500, 2000, 2500), .nodesize = seq(20, 100, 20))
tunegrid <- expand.grid(.ntree=c(1000, 1500, 2000, 2500), .nodesize = seq(20, 100, 20))
metric <- "Accuracy"
customRF <- list(type = "Classification", library = "randomForest", loop = NULL)
customRF$parameters <- data.frame(parameter = c("ntree", "nodesize"), class = rep("numeric", 2), label = c("mtry", "ntree", "nodesize"))
customRF$grid <- function(x, y, len = NULL, search = "grid") {}
customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
randomForest(x, y, ntree=param$ntree, nodesize = param$nodesize, ...)
}
customRF <- list(type = "Classification", library = "randomForest", loop = NULL)
customRF$parameters <- data.frame(parameter = c("ntree", "nodesize"), class = rep("numeric", 2), label = c("ntree", "nodesize"))
customRF$grid <- function(x, y, len = NULL, search = "grid") {}
customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
randomForest(x, y, ntree=param$ntree, nodesize = param$nodesize, ...)
}
customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata)
customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata, type = "prob")
customRF$sort <- function(x) x[order(x[,1]),]
customRF$levels <- function(x) x$classes
control <- trainControl(method="cv", number=5)
set.seed(123)
custom <- train(income ~ ., data=train_origin, method=customRF, metric=metric, tuneGrid=tunegrid, trControl=control, mtry = 16)
custom <- train(income ~ ., data=train_origin, method=customRF, metric=metric, tuneGrid=tunegrid, trControl=control)
rm(rfParam)
cl = makeCluster(detectCores()-1)
registerDoParallel(cl)
control <- trainControl(method="cv", number=5)
set.seed(123)
custom <- train(income ~ ., data=train_origin, method=customRF, metric=metric, tuneGrid=tunegrid, trControl=control)
summary(train_origin)
custom <- train(income ~ ., data=train_origin, method=customRF, tuneGrid=tunegrid, trControl=control)
custom <- train(x = xtrain_origin, y = ytrain_origin, method=customRF, tuneGrid=tunegrid, trControl=control)
custom <- train(x = xtrain_origin, y = ytrain_origin, method=customRF, tuneGrid=tunegrid, trControl=control
mtry = 16)
custom <- train(x = xtrain_origin, y = ytrain_origin, method=customRF, tuneGrid=tunegrid, trControl=control,
mtry = 16)
customRF <- list(type = "Classification", library = "randomForest", loop = NULL)
customRF$parameters <- data.frame(parameter = c("mtry", "ntree", "nodesize"), class = rep("numeric", 3), label = c("mtry", "ntree", "nodesize"))
customRF$grid <- function(x, y, len = NULL, search = "grid") {}
customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
randomForest(x, y, mtry = param$mtry, ntree=param$ntree, nodesize = param$nodesize, ...)
}
customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata)
customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata, type = "prob")
customRF$sort <- function(x) x[order(x[,1]),]
customRF$levels <- function(x) x$classes
tunegrid <- expand.grid(.mtry = 16, .ntree=c(1000, 1500, 2000, 2500), .nodesize = seq(20, 100, 20))
tunegrid
control <- trainControl(method="cv", number=5)
set.seed(123)
custom <- train(x = xtrain_origin, y = ytrain_origin, method=customRF, tuneGrid=tunegrid, trControl=control,
mtry = 16)
custom <- train(x = xtrain_origin, y = ytrain_origin, method=customRF, tuneGrid=tunegrid, trControl=control)
tunegrid <- expand.grid(.mtry = c(15:16), .ntree=c(1000, 1500, 2000, 2500), .nodesize = seq(20, 100, 20))
custom <- train(x = xtrain_origin, y = ytrain_origin, method=customRF, tuneGrid=tunegrid, trControl=control)
tunegrid <- expand.grid(.mtry = c(15:16), .ntree=c(1000, 1500, 2000, 2500))
tunegrid <- expand.grid(.mtry = c(15:16), .ntree=c(1000, 1500, 2000, 2500))
metric <- "Accuracy"
customRF <- list(type = "Classification", library = "randomForest", loop = NULL)
customRF$parameters <- data.frame(parameter = c("mtry", "ntree"), class = rep("numeric", 2), label = c("mtry", "ntree"))
customRF$grid <- function(x, y, len = NULL, search = "grid") {}
customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
randomForest(x, y, mtry = param$mtry, ntree=param$ntree, ...)
}
customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata)
customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata, type = "prob")
customRF$sort <- function(x) x[order(x[,1]),]
customRF$levels <- function(x) x$classes
control <- trainControl(method="cv", number=5)
set.seed(123)
custom <- train(x = xtrain_origin, y = ytrain_origin, method=customRF, tuneGrid=tunegrid, trControl=control)
customRF <- list(type = "Classification", library = "randomForest", loop = NULL)
customRF$parameters <- data.frame(parameter = c("mtry", "ntree"), class = rep("numeric", 2), label = c("mtry", "ntree"))
customRF$grid <- function(x, y, len = NULL, search = "grid") {}
customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
randomForest(x, y, mtry = param$mtry, ntree=param$ntree, ...)
}
customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata)
customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata, type = "prob")
customRF$sort <- function(x) x[order(x[,1]),]
customRF$levels <- function(x) x$classes
table(train_origin$income)
table(train_origin$income, test_origin$income)
control <- trainControl(method="cv", number=5)
tunegrid <- expand.grid(.mtry=c(1:15), .ntree=c(1000, 1500, 2000, 2500))
custom <- train(income ~ ., data=train_origin, method=customRF, metric=metric, tuneGrid=tunegrid, trControl=control)
tunegrid <- expand.grid(.mtry=c(1:16), .ntree=c(1000, 1500, 2000, 2500))
custom <- train(income ~ ., data=train_origin, method=customRF, metric=metric, tuneGrid=tunegrid, trControl=control)
custom <- train(income ~ ., data=train_origin, method="customRF", metric=metric, tuneGrid=tunegrid, trControl=control)
custom <- train(income ~ ., data=train_origin, method="treebag", metric=metric, tuneGrid=tunegrid, trControl=control)
cartModel$variable.importance
cartModel <- rpart(income ~., train_origin)
cartModel$variable.importance
printcp(cartModel)
plot(cartModel)
text(cartModel, cex = 0.5)
custom <- train(income ~ ., data=train_origin, method="treebag", metric=metric, trControl=control)
library(ipred)
control = trainControl(method = "cv", number = 5)
rf_default  = train(x = xtrain_origin, y = ytrain_origin,
method = "treebag", trControl = control,
importance= T, ntree = 100, replace= F, mtry = ncol(xtrain_origin))
rf_default
control2 = trainControl(method = "cv", number = 5, search = "grid", allowParallel = TRUE)
tunegrid = expand.grid(.ntrees = seq(50, 300, 50))
rf_gridsearch = train(xtrain_origin, ytrain_origin, method = "treebag",
tuneGrid=tunegrid, mtry = ncol(xtrain_origin),
trControl=control2)
?toString
metric <- "Accuracy"
control <- trainControl(method="cv", number=5, search="grid")
tunegrid <- expand.grid(.mtry=ncol(x))
tunegrid <- expand.grid(.mtry=ncol(xtrain_origin))
for (ntree in seq(50, 500, 50)) {
for(nodesize in c(1,5,10,50,100, 200, 250, 500)){
set.seed(seed)
fit <- train(income~., data=train_origin, method="rf", metric=metric,
tuneGrid=tunegrid, trControl=control, ntree=ntree,
nodesize = nodesize)
key <- toString(ntree)
modellist[[key]] <- fit
}
}
seed <- 123
for (ntree in seq(50, 500, 50)) {
for(nodesize in c(1,5,10,50,100, 200, 250, 500)){
set.seed(seed)
fit <- train(income~., data=train_origin, method="rf", metric=metric,
tuneGrid=tunegrid, trControl=control, ntree=ntree,
nodesize = nodesize)
key <- toString(ntree)
modellist[[key]] <- fit
}
}
metric <- "Accuracy"
control <- trainControl(method="cv", number=5, search="grid")
tunegrid <- expand.grid(.mtry=ncol(xtrain_origin))
seed <- 123
modellist <- list()
for (ntree in seq(50, 500, 50)) {
for(nodesize in c(1,5,10,50,100, 200, 250, 500)){
set.seed(seed)
fit <- train(income~., data=train_origin, method="rf", metric=metric,
tuneGrid=tunegrid, trControl=control, ntree=ntree,
nodesize = nodesize)
key <- toString(ntree)
modellist[[key]] <- fit
}
}
metric <- "Accuracy"
control <- trainControl(method="cv", number=5, search="grid")
tunegrid <- expand.grid(.mtry=ncol(xtrain_origin))
seed <- 123
modellist <- list()
for (ntree in seq(50, 500, 50)) {
set.seed(seed)
fit <- train(income~., data=train_origin, method="rf", metric=metric,
tuneGrid=tunegrid, trControl=control, ntree=ntree)
key <- toString(ntree)
modellist[[key]] <- fit
}
modellist
results <- resamples(modellist)
summary(results)
control <- trainControl(method="cv", number=5, search="grid")
tunegrid <- expand.grid(.mtry=ncol(xtrain_origin))
seed <- 123
modellist <- list()
for (ntree in c(1,5,10,50,100)) {
set.seed(seed)
fit <- train(income~., data=train_origin, method="rf", metric=metric,
tuneGrid=tunegrid, trControl=control, ntree=ntree)
key <- toString(ntree)
modellist[[key]] <- fit
}
results <- resamples(modellist)
summary(results)
dotplot(results)
control <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")
for (ntree in c(1,5,10,50,100)) {
set.seed(seed)
fit <- train(income~., data=train_origin, method="rf", metric=metric,
tuneGrid=tunegrid, trControl=control, ntree=ntree)
key <- toString(ntree)
modellist[[key]] <- fit
}
ntree_test <- seq(50, 500, 50)
accuracies <- vector()
for(i in 1: length(ntree_test)){
bag <- randomForest(income~., data = train_origin, mtry = 16, importance = TRUE, ntree = ntree_test[i])
yhat.bag = predict(bag, newdata = test_origin)
test <- confusionMatrix(ytest_origin, yhat.bag, positive = "More.50k")
accuracies[i] <- (test$table[1] + test$table[4])/sum(test$table) #accuracy rate
}
train_origin <- as.data.frame(train_origin)
for(i in 1: length(ntree_test)){
bag <- randomForest(income~., data = train_origin, mtry = 16, importance = TRUE, ntree = ntree_test[i])
yhat.bag = predict(bag, newdata = test_origin)
test <- confusionMatrix(ytest_origin, yhat.bag, positive = "More.50k")
accuracies[i] <- (test$table[1] + test$table[4])/sum(test$table) #accuracy rate
}
head(train_origin)
train_origin <- data.frame(train_origin)
head(train_origin)
for(i in 1: length(ntree_test)){
bag <- randomForest(income~., data = train_origin, mtry = 16, importance = TRUE, ntree = ntree_test[i])
yhat.bag = predict(bag, newdata = test_origin)
test <- confusionMatrix(ytest_origin, yhat.bag, positive = "More.50k")
accuracies[i] <- (test$table[1] + test$table[4])/sum(test$table) #accuracy rate
}
head(train_origin)
head(test_origin)
names(test_origin)
names(test_origin) <- names(train_origin)
for(i in 1: length(ntree_test)){
bag <- randomForest(income~., data = train_origin, mtry = 16, importance = TRUE, ntree = ntree_test[i])
yhat.bag = predict(bag, newdata = test_origin)
test <- confusionMatrix(ytest_origin, yhat.bag, positive = "More.50k")
accuracies[i] <- (test$table[1] + test$table[4])/sum(test$table) #accuracy rate
}
stopCluster(cl = NULL)
stopCluster(cl = NULL)
?stopcluster
?stopCluster()
stopCluster(cl = NULL)
getDoParWorkers()
cl
stopCluster(cl)
getDoParWorkers()
